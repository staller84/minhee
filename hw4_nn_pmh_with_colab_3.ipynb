{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw4_nn_pmh_with_colab_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/staller84/minhee/blob/master/hw4_nn_pmh_with_colab_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KPdJ4Esdjil",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "407461c5-7dec-4022-db15-e17b676490c2"
      },
      "source": [
        "import numpy as np\n",
        "from skimage.util.shape import view_as_windows\n",
        "\n",
        "\n",
        "#######\n",
        "# if necessary, you can define additional functions which help your implementation,\n",
        "#  and import proper libraries for those functions.\n",
        "#######\n",
        "\n",
        "class nn_convolutional_layer:\n",
        "\n",
        "\n",
        "    def __init__(self, filter_width, filter_height, input_size, in_ch_size, num_filters, std=1e0):\n",
        "        #  filter_width : 3, filter_height : 3, input_size : 32, in_ch_size = 3, num_filters : 8,  batch_size : 8 \n",
        "        # initialization of weights\n",
        "        self.W = np.random.normal(0, std / np.sqrt(in_ch_size * filter_width * filter_height / 2),\n",
        "                                  (num_filters, in_ch_size, filter_width, filter_height))    # w = (8*3*3*3)\n",
        "        self.b = 0.01 + np.zeros((1, num_filters, 1, 1))  # b = 1*8*1*1  \n",
        "        self.input_size = input_size\n",
        "\n",
        "        #######\n",
        "        ## If necessary, you can define additional class variables here\n",
        "        #######\n",
        "        self.filter_width  = filter_width \n",
        "        self.filter_height = filter_height\n",
        "        self.num_filters   = num_filters\n",
        "        self.in_ch_size    = in_ch_size\n",
        "\n",
        "    def update_weights(self, dW, db):\n",
        "        self.W += dW\n",
        "        self.b += db\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.W, self.b\n",
        "\n",
        "    def set_weights(self, W, b):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "\n",
        "    #######\n",
        "    # Q1. Complete this method\n",
        "    #######\n",
        "    def forward(self, x):\n",
        "\n",
        "        y = view_as_windows(x, (8,3,3,3))  # (x.shape[0], x.shape[1], self.filter_width, self.filter_height)  \n",
        "        # convolution 연산 수행 (window : 8, 3, 3, 3)))  -> input 32 -> output (32-3+1=30) -> y (8(batch), 8(n_filter), 30, 30)\n",
        "        # print('y : ', y.shape) # y_shape :  (1, 1, 30, 30, 8, 3, 3, 3)  \n",
        "\n",
        "        # y, filter -> reshape \n",
        "        y = y.reshape (1, 1, 30, 30, 8, -1)  # (1,1,30,30,8,27)\n",
        "        # print('y1 : ', y.shape)\n",
        "\n",
        "        W = self.W.reshape(8, -1) # (8,27)\n",
        "        # print('W : ', W.shape)\n",
        "\n",
        "        rst = y @ W.T # (1,1,30,30,8,27)@(27,8)=(1,1,30,30,8,8)\n",
        "        # print('rst1 : ', rst.shape)\n",
        "\n",
        "        # squeeze (차원축소, axis 안주면 차원 중 사이즈가 1인 것을 찾아 스칼라값으로 바꿔 해당 차원을 제거한다)\n",
        "        rst = rst.squeeze()   # (1,1,width_size, height_size, batch_size, num_filter) -> (width_size, height_size, batch_size, num_filter)\n",
        "        # transpose(rst, (index 순서대로)) 원소의 index를 재배열    \n",
        "        rst = np.transpose(rst,(2,3,0,1))  # (8,8,30,30) =  batch_size, num_filter_size, width_size, height_size \n",
        "        rst = rst + self.b   # wx + b \n",
        "        # print('rst2 : ', rst.shape)  # (8,8,30,30)\n",
        "\n",
        "        return rst \n",
        "\n",
        "    #######\n",
        "    # Q2. Complete this method\n",
        "    # http://taewan.kim/post/cnn/\n",
        "    # https://wiseodd.github.io/techblog/2016/07/16/convnet-conv-layer/\n",
        "    #######\n",
        "    # dLdx : q(dLdy,상수)를 padding -> w를 inverse -> convolution \n",
        "    # dLdw : x 와 dLdy를 convolution \n",
        "    # dLdb : np.sum(q) q의 모든 값을 더해준다 (모두 상수니) \n",
        "\n",
        "    def backprop(self, x, dLdy):\n",
        "\n",
        "        # 1. dLdx : q(dLdy,상수)를 padding -> w를 inverse -> convolution \n",
        "        # 1-1) padding 처리  : https://dhhwang89.tistory.com/101\n",
        "        # (batch_size, num_filter_size, width_size, height_size) 중 width_size, height_size 만 처리.\n",
        "        pad = 2\n",
        "        npad = ((0, 0), (0, 0), (pad, pad), (pad, pad))\n",
        "        padding_dLdy = np.pad(dLdy, npad, 'constant', constant_values=(0))\n",
        "        # print ('padding_dLdy : ', padding_dLdy.shape)\n",
        "\n",
        "        dLdy_view = view_as_windows(padding_dLdy, (8,8,3,3)) # padding_dLdy.shape[0], padding_dLdy.shape[1], self.filter_width, self.filter_height\n",
        "        # (batch size, num filter, width_size, height_size) (8,8,30,30)\n",
        "\n",
        "        # 1-2) w 를 inverse처리 \n",
        "        w_1 = np.flip(self.W, (2,3)) # reverse w. 0=batch size, 1=num filters는 그대로 두고 나머지만 (q) 바꾼다.\n",
        "        dLdy_view = dLdy_view.reshape(dLdy_view.shape[0], dLdy_view.shape[1], dLdy_view.shape[2], dLdy_view.shape[3], dLdy_view.shape[4], -1)   \n",
        "        w_1 = w_1.transpose(1,0,2,3)    # 순서변경 :  in_ch_size, num_filter, filter_width, filter_heigh\n",
        "        w_1 = w_1.reshape(w_1.shape[0], -1) # 계산이 쉽게 flat 하게 변경\n",
        "\n",
        "        # 1-3) convolution 진행 (dLdy @ W inverse)\n",
        "        dLdx = dLdy_view @ w_1.T     \n",
        "        dLdx = dLdx.squeeze()\n",
        "        dLdx = dLdx.transpose(2,3,0,1)\n",
        "        # print ('dLdx : ', dLdx.shape)\n",
        "\n",
        "\n",
        "        # 2. dLdw : x 와 dLdy를 convolution \n",
        "        # 2-1) x : (batch size 8, input channel size 3 , in width 32, in height 32) \n",
        "        x_view = view_as_windows(x, (dLdy.shape[0],self.in_ch_size, dLdy.shape[2], dLdy.shape[3]))\n",
        "        # in_ch_size, view_out_width, view_out_height, batch_size, filter(dLdy)_width, filter(dLdy)_height\n",
        "        x_view = x_view.transpose (0, 1, 5, 2, 3, 4, 6, 7)\n",
        "        x_view = x_view.reshape(x_view.shape[0], x_view.shape[1], x_view.shape[2], x_view.shape[3], x_view.shape[3], -1)\n",
        "\n",
        "        # 2-2) dLdy :  (batch size 8, num filter 8, out width 30, out height 30)  \n",
        "        dLdy_flat = dLdy.transpose(1,0,2,3)\n",
        "        dLdy_flat = dLdy_flat.reshape(dLdy_flat.shape[0], -1)\n",
        "        # print ('dLdy_flat : ', dLdy_flat.shape)\n",
        "\n",
        "        # 2-3) convolution\n",
        "        dLdW = x_view @ dLdy_flat.T\n",
        "        # print('dLdW1 :', dLdW.shape)\n",
        "        dLdW = dLdW.squeeze()\n",
        "        dLdW = dLdW.transpose (3, 0, 1, 2)\n",
        "        # (num_filters, in_ch_size, filter_width, filter_height)\n",
        "        # print('dLdW2 shape :', dLdW.shape)\n",
        "      \n",
        "        # 3. dLdb : np.sum(q) q의 모든 값을 더해준다 (모두 상수) \n",
        "        dLdb = np.sum(dLdy, (0,2,3))  # filter의 갯수는 제외 후 더하기 axis=1\n",
        "        dLdb = dLdb.reshape(self.b.shape)  # (1, 8, 1, 1)\n",
        "        # print ('dLdb : ', dLdb.shape)\n",
        "\n",
        "        return dLdx, dLdW, dLdb\n",
        "\n",
        "\n",
        "class nn_max_pooling_layer:\n",
        "    def __init__(self, stride, pool_size):\n",
        "        self.stride = stride\n",
        "        self.pool_size = pool_size\n",
        "        #######\n",
        "        ## If necessary, you can define additional class variables here\n",
        "        #######\n",
        "\n",
        "    #######\n",
        "    # Q3. Complete this method\n",
        "    #######\n",
        "    def forward(self, x):\n",
        "        y = view_as_windows(x, (x.shape[0], x.shape[1], self.pool_size, self.pool_size), self.stride)\n",
        "        y = y.squeeze()\n",
        "        y = y.reshape(y.shape[0], y.shape[1], y.shape[2], y.shape[3], -1)\n",
        "        rst = y.max(axis=4)\n",
        "        self.max_id = y.argmax(axis=4)\n",
        "        self.max_id = self.max_id.transpose(2, 3, 0, 1)\n",
        "\n",
        "        rst = rst.transpose(2, 3, 0, 1)\n",
        "        return rst\n",
        "\n",
        "    #######\n",
        "    # Q4. Complete this method\n",
        "    #######\n",
        "    def backprop(self, x, dLdy):\n",
        "\n",
        "        cal = np.zeros_like(x).astype(float)\n",
        "        for i in np.arange(self.max_id.shape[0]):\n",
        "            for j in np.arange(self.max_id.shape[1]):\n",
        "                for k in np.arange(self.max_id.shape[2]):\n",
        "                    for l in np.arange(self.max_id.shape[3]):\n",
        "                        n = int(np.floor(self.max_id[i,j,k,l] / self.pool_size))\n",
        "                        m = int (self.max_id[i,j,k,l] % self.pool_size)\n",
        "                        cal[i,j, self.pool_size*k+n, self.pool_size*l+m] = dLdy[i,j,k,l]\n",
        "\n",
        "        dLdx = cal\n",
        "        return dLdx\n",
        "\n",
        "    #######\n",
        "    ## If necessary, you can define additional class methods here\n",
        "    #######\n",
        "\n",
        "\n",
        "# testing the implementation\n",
        "\n",
        "# data sizes\n",
        "batch_size = 8\n",
        "input_size = 32\n",
        "filter_width = 3\n",
        "filter_height = filter_width\n",
        "in_ch_size = 3\n",
        "num_filters = 8\n",
        "\n",
        "std = 1e0\n",
        "dt = 1e-3\n",
        "\n",
        "# number of test loops\n",
        "num_test = 20\n",
        "\n",
        "# error parameters\n",
        "err_dLdb = 0\n",
        "err_dLdx = 0\n",
        "err_dLdW = 0\n",
        "err_dLdx_pool = 0\n",
        "\n",
        "for i in range(num_test):\n",
        "    # create convolutional layer object\n",
        "    cnv = nn_convolutional_layer(filter_width, filter_height, input_size, in_ch_size, num_filters, std)\n",
        "\n",
        "    x = np.random.normal(0, 1, (batch_size, in_ch_size, input_size, input_size))\n",
        "    delta = np.random.normal(0, 1, (batch_size, in_ch_size, input_size, input_size)) * dt\n",
        "\n",
        "    # dLdx test\n",
        "    print('dLdx test')\n",
        "    y1 = cnv.forward(x)\n",
        "    y2 = cnv.forward(x + delta)\n",
        "\n",
        "    bp, _, _ = cnv.backprop(x, np.ones(y1.shape))\n",
        "\n",
        "    exact_dx = np.sum(y2 - y1) / dt\n",
        "    apprx_dx = np.sum(delta * bp) / dt\n",
        "    print('exact change', exact_dx)\n",
        "    print('apprx change', apprx_dx)\n",
        "\n",
        "    err_dLdx += abs((apprx_dx - exact_dx) / exact_dx) / num_test * 100\n",
        "\n",
        "    # dLdW test\n",
        "    print('dLdW test')\n",
        "    W, b = cnv.get_weights()\n",
        "    dW = np.random.normal(0, 1, W.shape) * dt\n",
        "    db = np.zeros(b.shape)\n",
        "\n",
        "    z1 = cnv.forward(x)\n",
        "    _, bpw, _ = cnv.backprop(x, np.ones(z1.shape))\n",
        "    cnv.update_weights(dW, db)\n",
        "    z2 = cnv.forward(x)\n",
        "\n",
        "    exact_dW = np.sum(z2 - z1) / dt\n",
        "    apprx_dW = np.sum(dW * bpw) / dt\n",
        "    print('exact change', exact_dW)\n",
        "    print('apprx change', apprx_dW)\n",
        "\n",
        "    err_dLdW += abs((apprx_dW - exact_dW) / exact_dW) / num_test * 100\n",
        "\n",
        "    # dLdb test\n",
        "    print('dLdb test')\n",
        "\n",
        "    W, b = cnv.get_weights()\n",
        "\n",
        "    dW = np.zeros(W.shape)\n",
        "    db = np.random.normal(0, 1, b.shape) * dt\n",
        "\n",
        "    z1 = cnv.forward(x)\n",
        "\n",
        "    V = np.random.normal(0, 1, z1.shape)\n",
        "\n",
        "    _, _, bpb = cnv.backprop(x, V)\n",
        "\n",
        "    cnv.update_weights(dW, db)\n",
        "    z2 = cnv.forward(x)\n",
        "\n",
        "    exact_db = np.sum(V * (z2 - z1) / dt)\n",
        "    apprx_db = np.sum(db * bpb) / dt\n",
        "\n",
        "    print('exact change', exact_db)\n",
        "    print('apprx change', apprx_db)\n",
        "    err_dLdb += abs((apprx_db - exact_db) / exact_db) / num_test * 100\n",
        "\n",
        "    # max pooling test\n",
        "    # parameters for max pooling\n",
        "    stride = 2\n",
        "    pool_size = 2\n",
        "\n",
        "    mpl = nn_max_pooling_layer(stride=stride, pool_size=pool_size)\n",
        "\n",
        "    x = np.arange(batch_size * in_ch_size * input_size * input_size).reshape(\n",
        "        (batch_size, in_ch_size, input_size, input_size)) + 1\n",
        "    delta = np.random.normal(0, 1, (batch_size, in_ch_size, input_size, input_size)) * dt\n",
        "\n",
        "    print('dLdx test for pooling')\n",
        "    y1 = mpl.forward(x) #(8, 3, 16, 16)\n",
        "    dLdy = np.random.normal(0, 10, y1.shape)\n",
        "    bpm = mpl.backprop(x, dLdy)\n",
        "\n",
        "    y2 = mpl.forward(x + delta)\n",
        "\n",
        "    exact_dx_pool = np.sum(dLdy * (y2 - y1)) / dt\n",
        "    apprx_dx_pool = np.sum(delta * bpm) / dt\n",
        "    print('exact change', exact_dx_pool)\n",
        "    print('apprx change', apprx_dx_pool)\n",
        "\n",
        "    err_dLdx_pool += abs((apprx_dx_pool - exact_dx_pool) / exact_dx_pool) / num_test * 100\n",
        "\n",
        "# reporting accuracy results.\n",
        "print('accuracy results')\n",
        "print('conv layer dLdx', 100 - err_dLdx, '%')\n",
        "print('conv layer dLdW', 100 - err_dLdW, '%')\n",
        "print('conv layer dLdb', 100 - err_dLdb, '%')\n",
        "print('maxpool layer dLdx', 100 - err_dLdx_pool, '%')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dLdx test\n",
            "exact change 461.11104977408536\n",
            "apprx change 461.1110497740586\n",
            "dLdW test\n",
            "exact change 3565.04967421296\n",
            "apprx change 3565.0496742129926\n",
            "dLdb test\n",
            "exact change 39.97687933679555\n",
            "apprx change 39.97687933678098\n",
            "dLdx test for pooling\n",
            "exact change 148.08934442882978\n",
            "apprx change 148.0893445543903\n",
            "dLdx test\n",
            "exact change -219.11107699563462\n",
            "apprx change -219.11107699569922\n",
            "dLdW test\n",
            "exact change 54.68333767686775\n",
            "apprx change 54.68333767689604\n",
            "dLdb test\n",
            "exact change -217.5668117061187\n",
            "apprx change -217.56681170612023\n",
            "dLdx test for pooling\n",
            "exact change 144.07517017340209\n",
            "apprx change 144.07517064192425\n",
            "dLdx test\n",
            "exact change 457.43233603645524\n",
            "apprx change 457.43233603657717\n",
            "dLdW test\n",
            "exact change -258.97503877123796\n",
            "apprx change -258.97503877113945\n",
            "dLdb test\n",
            "exact change 376.8919130567085\n",
            "apprx change 376.8919130566851\n",
            "dLdx test for pooling\n",
            "exact change -726.9507508633988\n",
            "apprx change -726.950750951918\n",
            "dLdx test\n",
            "exact change -148.78660204799695\n",
            "apprx change -148.7866020478754\n",
            "dLdW test\n",
            "exact change -655.335009630135\n",
            "apprx change -655.3350096300967\n",
            "dLdb test\n",
            "exact change 149.64698977904055\n",
            "apprx change 149.64698977908196\n",
            "dLdx test for pooling\n",
            "exact change -517.1787660599676\n",
            "apprx change -517.1787659488036\n",
            "dLdx test\n",
            "exact change 193.6806896756097\n",
            "apprx change 193.68068967564992\n",
            "dLdW test\n",
            "exact change 168.8526726888801\n",
            "apprx change 168.85267268881876\n",
            "dLdb test\n",
            "exact change -159.12585758210383\n",
            "apprx change -159.12585758215283\n",
            "dLdx test for pooling\n",
            "exact change -659.9539959914629\n",
            "apprx change -659.9539966216196\n",
            "dLdx test\n",
            "exact change 219.30950370305177\n",
            "apprx change 219.3095037030587\n",
            "dLdW test\n",
            "exact change 29.620886750529476\n",
            "apprx change 29.620886750658173\n",
            "dLdb test\n",
            "exact change -23.79550021901364\n",
            "apprx change -23.795500218969423\n",
            "dLdx test for pooling\n",
            "exact change -364.33364490561195\n",
            "apprx change -364.3336448785149\n",
            "dLdx test\n",
            "exact change -296.2022660448695\n",
            "apprx change -296.2022660448281\n",
            "dLdW test\n",
            "exact change 289.5444085709208\n",
            "apprx change 289.54440857081534\n",
            "dLdb test\n",
            "exact change -67.98365956164952\n",
            "apprx change -67.98365956169185\n",
            "dLdx test for pooling\n",
            "exact change -1427.7119048673114\n",
            "apprx change -1427.7119056076212\n",
            "dLdx test\n",
            "exact change -71.57842166983706\n",
            "apprx change -71.57842166987449\n",
            "dLdW test\n",
            "exact change -735.8290819694292\n",
            "apprx change -735.8290819693682\n",
            "dLdb test\n",
            "exact change 114.7457001313757\n",
            "apprx change 114.7457001313885\n",
            "dLdx test for pooling\n",
            "exact change 461.00355790454097\n",
            "apprx change 461.0035579484063\n",
            "dLdx test\n",
            "exact change 21.621949040169778\n",
            "apprx change 21.62194904010186\n",
            "dLdW test\n",
            "exact change 443.84456276839745\n",
            "apprx change 443.8445627684047\n",
            "dLdb test\n",
            "exact change 732.173482157877\n",
            "apprx change 732.1734821578727\n",
            "dLdx test for pooling\n",
            "exact change 803.7291541855928\n",
            "apprx change 803.7291541135822\n",
            "dLdx test\n",
            "exact change -122.27176983967053\n",
            "apprx change -122.27176983969802\n",
            "dLdW test\n",
            "exact change 684.4826144631055\n",
            "apprx change 684.4826144630886\n",
            "dLdb test\n",
            "exact change -94.23186948109051\n",
            "apprx change -94.23186948111963\n",
            "dLdx test for pooling\n",
            "exact change -68.09774629827051\n",
            "apprx change -68.09774631503387\n",
            "dLdx test\n",
            "exact change -42.23986340030822\n",
            "apprx change -42.23986340031737\n",
            "dLdW test\n",
            "exact change 1263.4754350934672\n",
            "apprx change 1263.4754350935295\n",
            "dLdb test\n",
            "exact change -86.06198699401054\n",
            "apprx change -86.06198699403865\n",
            "dLdx test for pooling\n",
            "exact change -943.0650435364789\n",
            "apprx change -943.0650429766081\n",
            "dLdx test\n",
            "exact change -36.1557358472617\n",
            "apprx change -36.15573584719457\n",
            "dLdW test\n",
            "exact change 175.04228707218897\n",
            "apprx change 175.0422870720063\n",
            "dLdb test\n",
            "exact change -31.024048878998567\n",
            "apprx change -31.02404887898194\n",
            "dLdx test for pooling\n",
            "exact change 1320.6641633405607\n",
            "apprx change 1320.6641640878772\n",
            "dLdx test\n",
            "exact change -33.20094065633276\n",
            "apprx change -33.20094065628995\n",
            "dLdW test\n",
            "exact change -1976.455145281698\n",
            "apprx change -1976.4551452816747\n",
            "dLdb test\n",
            "exact change -82.16576560835374\n",
            "apprx change -82.16576560837252\n",
            "dLdx test for pooling\n",
            "exact change -12.569778701208344\n",
            "apprx change -12.569779025543347\n",
            "dLdx test\n",
            "exact change 318.2016665581018\n",
            "apprx change 318.201666558187\n",
            "dLdW test\n",
            "exact change 45.741130535834856\n",
            "apprx change 45.7411305357644\n",
            "dLdb test\n",
            "exact change 63.879681769350455\n",
            "apprx change 63.879681769321614\n",
            "dLdx test for pooling\n",
            "exact change -792.2960980952406\n",
            "apprx change -792.2960975306797\n",
            "dLdx test\n",
            "exact change 353.61935905746975\n",
            "apprx change 353.61935905733696\n",
            "dLdW test\n",
            "exact change 1423.2872197253794\n",
            "apprx change 1423.2872197252252\n",
            "dLdb test\n",
            "exact change 181.8039100049988\n",
            "apprx change 181.80391000497343\n",
            "dLdx test for pooling\n",
            "exact change 483.43935275442243\n",
            "apprx change 483.4393524681333\n",
            "dLdx test\n",
            "exact change 76.60936371894432\n",
            "apprx change 76.60936371895984\n",
            "dLdW test\n",
            "exact change 484.14728125083735\n",
            "apprx change 484.14728125088203\n",
            "dLdb test\n",
            "exact change -295.88452277586265\n",
            "apprx change -295.88452277589215\n",
            "dLdx test for pooling\n",
            "exact change -1048.2872632886938\n",
            "apprx change -1048.2872621418112\n",
            "dLdx test\n",
            "exact change 158.93003478501979\n",
            "apprx change 158.93003478492733\n",
            "dLdW test\n",
            "exact change -359.57908574093386\n",
            "apprx change -359.57908574099935\n",
            "dLdb test\n",
            "exact change 267.3764233736812\n",
            "apprx change 267.3764233737032\n",
            "dLdx test for pooling\n",
            "exact change 518.7850278521513\n",
            "apprx change 518.7850275560169\n",
            "dLdx test\n",
            "exact change 27.25363930213375\n",
            "apprx change 27.253639302128185\n",
            "dLdW test\n",
            "exact change 641.7698934196512\n",
            "apprx change 641.7698934196804\n",
            "dLdb test\n",
            "exact change -87.38478533241016\n",
            "apprx change -87.38478533239214\n",
            "dLdx test for pooling\n",
            "exact change -975.6817259334176\n",
            "apprx change -975.6817251486239\n",
            "dLdx test\n",
            "exact change -31.06495144618381\n",
            "apprx change -31.064951446066647\n",
            "dLdW test\n",
            "exact change -356.46989077663375\n",
            "apprx change -356.46989077649215\n",
            "dLdb test\n",
            "exact change 30.99600143211988\n",
            "apprx change 30.996001432105714\n",
            "dLdx test for pooling\n",
            "exact change 1531.0764147540856\n",
            "apprx change 1531.0764143921895\n",
            "dLdx test\n",
            "exact change -92.04070819574555\n",
            "apprx change -92.04070819586879\n",
            "dLdW test\n",
            "exact change -935.1895479927003\n",
            "apprx change -935.1895479926819\n",
            "dLdb test\n",
            "exact change 70.0104213308143\n",
            "apprx change 70.01042133085097\n",
            "dLdx test for pooling\n",
            "exact change 436.40227999707827\n",
            "apprx change 436.40227962843176\n",
            "accuracy results\n",
            "conv layer dLdx 99.99999999992096 %\n",
            "conv layer dLdW 99.99999999995174 %\n",
            "conv layer dLdb 99.99999999996511 %\n",
            "maxpool layer dLdx 99.99999980883716 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmdDQCW_eQKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}